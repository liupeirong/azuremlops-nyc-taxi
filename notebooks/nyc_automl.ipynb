{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import joblib\n",
    "from azureml.core import Workspace, Datastore, Dataset, Experiment, Environment\n",
    "from azureml.core.model import Model, InferenceConfig\n",
    "from azureml.core.webservice import AksWebservice, Webservice\n",
    "from azureml.core.compute import AksCompute\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CODE_PATH = '../code'\n",
    "DATA_PATH = '../sample_data'\n",
    "DOWNLOAD_PATH = '../download'\n",
    "AML_UTIL_PATH = '../ml_service'\n",
    "sys.path.append(os.path.join(os.getcwd(), CODE_PATH))\n",
    "sys.path.append(os.path.join(os.getcwd(), AML_UTIL_PATH))\n",
    "import utils\n",
    "import consts\n",
    "import train\n",
    "import aml_utils as amlutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is only needed when we run in a Jupyter notebook and the external files are changed\n",
    "import importlib\n",
    "importlib.reload(utils)\n",
    "importlib.reload(consts)\n",
    "importlib.reload(train)\n",
    "importlib.reload(amlutils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config(path='../.azureml')\n",
    "experiment = Experiment(ws, 'nyctaxi_automl')\n",
    "compute_target_name = os.environ['AML_COMPUTE']\n",
    "inference_target_name = os.environ['AML_INFERENCE_COMPUTE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read raw data and prepare for training\n",
    "\n",
    "Read the raw data in the sample_data_folder if exists, or get it from Azure Open DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "RAW_DATA_PATH = os.path.join(DATA_PATH, 'raw')\n",
    "Path(RAW_DATA_PATH).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.strptime(\"1/1/2015\",\"%m/%d/%Y\")\n",
    "end = datetime.strptime(\"1/31/2015\",\"%m/%d/%Y\")\n",
    "\n",
    "DATA_FILE_NAME = '{}{:02d}_automl.csv'.format(start.year, start.month)\n",
    "RAW_DATA_FILE = os.path.join(RAW_DATA_PATH, DATA_FILE_NAME)\n",
    "\n",
    "if not os.path.isfile(RAW_DATA_FILE):\n",
    "    print (\"Downloading raw data from Azure Open dataset\")\n",
    "    from azureml.opendatasets import NycTlcGreen\n",
    "\n",
    "    # get Jan data first, later we will also predict on Jul data to detect if there's any drift\n",
    "\n",
    "    dfraw = pd.DataFrame([])\n",
    "\n",
    "    for sample_month in range(1):\n",
    "        temp_df_green = NycTlcGreen(start + relativedelta(months=sample_month), end + relativedelta(months=sample_month)) \\\n",
    "            .to_pandas_dataframe()\n",
    "        dfraw = dfraw.append(temp_df_green.sample(1000))\n",
    "\n",
    "    dfraw.to_csv(RAW_DATA_FILE)\n",
    "else:\n",
    "    print (\"Reading raw data from existing file\")\n",
    "    dfraw = utils.read_raw_data(RAW_DATA_FILE)\n",
    "\n",
    "dfraw.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain = utils.process_raw_data(dfraw)\n",
    "dftrain.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain.duration.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create AML datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastore_name = os.environ['AML_DATASTORE']\n",
    "try:\n",
    "    datastore = Datastore.get(ws, datastore_name=datastore_name)\n",
    "    print('datastore {} exists'.format(datastore_name))\n",
    "except Exception:\n",
    "    print('create datastore {}'.format(datastore_name))\n",
    "    container_name = os.environ[\"BLOB_CONTAINER\"]\n",
    "    account_name = os.environ[\"BLOB_ACCOUNTNAME\"]\n",
    "    account_key = os.environ[\"BLOB_ACCOUNT_KEY\"]\n",
    "\n",
    "    datastore = Datastore.register_azure_blob_container(\n",
    "        workspace=ws, \n",
    "        datastore_name=datastore_name, \n",
    "        container_name=container_name, \n",
    "        account_name=account_name,\n",
    "        account_key=account_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload prepared data so that it can be accessed when training remotely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train.split_data(dftrain)\n",
    "training = pd.concat([x_train, y_train], axis=1, join='inner')\n",
    "testing = pd.concat([x_test, y_test], axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_PATH = os.path.join(DATA_PATH, 'train')\n",
    "\n",
    "if os.path.exists(TRAIN_DATA_PATH):\n",
    "    import glob\n",
    "    print(\"Remove existing processed training data\")\n",
    "    files = glob.glob(os.path.join(TRAIN_DATA_PATH, '*'))\n",
    "    for f in files:\n",
    "        os.remove(f)\n",
    "else:\n",
    "    print(\"Create folder for training data\")\n",
    "    Path(TRAIN_DATA_PATH).mkdir(parents=True, exist_ok=True)                \n",
    "\n",
    "utils.write_train_data(training, TRAIN_DATA_PATH, DATA_FILE_NAME)\n",
    "datastore.upload_files(files=[os.path.join(TRAIN_DATA_PATH, DATA_FILE_NAME)], target_path='train', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train locally or remotely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.automl.core.featurization import FeaturizationConfig\n",
    "\n",
    "local_training = False\n",
    "\n",
    "featurization_config = FeaturizationConfig()\n",
    "featurization_config.add_column_purpose('passengerCount', 'Numeric')\n",
    "\n",
    "automl_settings = {\n",
    "     'task': 'regression',\n",
    "     'iterations': 20,\n",
    "     'iteration_timeout_minutes': 2,\n",
    "     'experiment_timeout_minutes': 20,\n",
    "     'whitelist_models': ['LightGBM'], \n",
    "     'primary_metric': 'normalized_root_mean_squared_error',\n",
    "     'n_cross_validations': 5,\n",
    "     'label_column_name': 'duration',\n",
    "     'verbosity': logging.INFO,\n",
    "     'preprocess': False,\n",
    "     'model_explainability': True,\n",
    "     'featurization': featurization_config\n",
    "}\n",
    "\n",
    "if local_training:\n",
    "    automl_config = AutoMLConfig(\n",
    "        training_data=training,\n",
    "        **automl_settings)\n",
    "else:\n",
    "    tabular_train_dataset = Dataset.Tabular.from_delimited_files(\n",
    "        path=[(datastore, os.path.join('train', DATA_FILE_NAME))])\n",
    "    compute_target = ws.compute_targets[compute_target_name]\n",
    "    \n",
    "    automl_config = AutoMLConfig(\n",
    "        path=CODE_PATH,\n",
    "        training_data=tabular_train_dataset,\n",
    "        compute_target=compute_target,\n",
    "        **automl_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train without a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = experiment.submit(automl_config, show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train remotely with a Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.automl.runtime import AutoMLStep\n",
    "\n",
    "TRAIN_STEP_NAME = 'nyc_automl_regression'\n",
    "\n",
    "trainWithAutoMLStep = AutoMLStep(\n",
    "    name=TRAIN_STEP_NAME,\n",
    "    automl_config=automl_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "pipeline_steps = [trainWithAutoMLStep]\n",
    "\n",
    "pipeline = Pipeline(workspace = ws, steps=pipeline_steps)\n",
    "print(\"Pipeline is built.\")\n",
    "\n",
    "pipeline_run = experiment.submit(pipeline, regenerate_outputs=False)\n",
    "print(\"Pipeline submitted for execution.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: REMOVE!\n",
    "from azureml.pipeline.core import PipelineRun\n",
    "pipeline_run = PipelineRun(experiment, \"37291ab0-e698-423f-bcec-d2a39b8d4b3b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.automl.run import AutoMLRun\n",
    "\n",
    "train_step_run = pipeline_run.find_step_run(TRAIN_STEP_NAME)[0]\n",
    "automl_run = AutoMLRun(experiment=experiment, run_id=train_step_run.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run, model = automl_run.get_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict(x_test)\n",
    "actual_vs_predicted = y_test.to_frame()\n",
    "actual_vs_predicted['predicted'] = y_predict\n",
    "actual_vs_predicted.sort_index().plot(figsize=(20, 5), rot=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "y_actual = y_test.values.flatten().tolist()\n",
    "rmse = sqrt(mean_squared_error(y_actual, y_predict))\n",
    "mape = utils.MAPE(y_test, y_predict)\n",
    "\n",
    "run.log('rmse', rmse)\n",
    "run.log('mape', mape)\n",
    "print(\"rmse:{0}, mape:{1}\".format(rmse, mape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('outputs', exist_ok=True)\n",
    "model_file = os.path.join('outputs', consts.model_name_automl)\n",
    "print('writing model file to {}'.format(model_file))\n",
    "joblib.dump(value=model, filename=model_file)\n",
    "if local_training:\n",
    "    run.upload_file(name=consts.model_name_automl, path_or_stream=model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publish the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "published_pipeline = pipeline_run.publish_pipeline(\n",
    "     name=\"NYCtaxi_pipeline\",\n",
    "     description=\"Pipeline to train NYC taxi data for duration prediction\",\n",
    "     version=\"1.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also publish a versioned endpoint of the pipeline\n",
    "from azureml.pipeline.core import PipelineEndpoint\n",
    "\n",
    "pipeline_endpoint = PipelineEndpoint.publish(workspace=ws, \n",
    "                                             name=\"NYCtaxi_pipeline_endpoint_notebook\",\n",
    "                                             pipeline=published_pipeline, \n",
    "                                             description=\"Pipeline endpoint from Notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.explain.model._internal.explanation_client import ExplanationClient\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "client = ExplanationClient.from_run(run)\n",
    "engineered_explanations = client.download_model_explanation(raw=False)\n",
    "global_importance = engineered_explanations.get_feature_importance_dict()\n",
    "l2h=dict(sorted(global_importance.items(), key=lambda x: x[1]))\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.barh(range(len(l2h)), l2h.values(), tick_label=list(l2h.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain the model for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.automl.runtime.automl_explain_utilities import automl_setup_model_explanations\n",
    "\n",
    "automl_explainer_setup_obj = automl_setup_model_explanations(model, X=x_train, \n",
    "                                                             X_test=x_test, y=y_train, \n",
    "                                                             task='regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.explain.model.mimic.models.lightgbm_model import LGBMExplainableModel\n",
    "from azureml.explain.model.mimic_wrapper import MimicWrapper\n",
    "\n",
    "# Initialize the Mimic Explainer\n",
    "engineered_explainer = MimicWrapper(ws, automl_explainer_setup_obj.automl_estimator, LGBMExplainableModel, \n",
    "                         init_dataset=automl_explainer_setup_obj.X_transform, run=run,\n",
    "                         features=automl_explainer_setup_obj.engineered_feature_names, \n",
    "                         feature_maps=[automl_explainer_setup_obj.feature_map])\n",
    "raw_explainer = MimicWrapper(ws, model, LGBMExplainableModel, \n",
    "                         init_dataset=x_train, \n",
    "                         run=run,\n",
    "                         features=automl_explainer_setup_obj.raw_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_explanations = explainer.explain(['local', 'global'], eval_dataset=x_test)\n",
    "raw_testdata_importance = raw_explanations.get_feature_importance_dict()\n",
    "l2h=dict(sorted(raw_testdata_importance.items(), key=lambda x: x[1]))\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.barh(range(len(l2h)), l2h.values(), tick_label=list(l2h.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engineered_explanations = engineered_explainer.explain(\n",
    "    ['local', 'global'], eval_dataset=automl_explainer_setup_obj.X_test_transform)\n",
    "testdata_importance = engineered_explanations.get_feature_importance_dict()\n",
    "l2h=dict(sorted(testdata_importance.items(), key=lambda x: x[1]))\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.barh(range(len(l2h)), l2h.values(), tick_label=list(l2h.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain the model during inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.interpret.scoring.scoring_explainer import TreeScoringExplainer, save, load\n",
    "\n",
    "# Initialize the ScoringExplainer\n",
    "#scoring_explainer = TreeScoringExplainer(explainer.explainer, feature_maps=[automl_explainer_setup_obj.feature_map])\n",
    "scoring_explainer = TreeScoringExplainer(raw_explainer.explainer)\n",
    "\n",
    "# Pickle scoring explainer locally\n",
    "save(scoring_explainer, directory='outputs', exist_ok=True)\n",
    "\n",
    "# Register scoring explainer\n",
    "run.upload_file('raw_scoring_explainer.pkl', 'outputs/scoring_explainer.pkl')\n",
    "scoring_explainer_model = run.register_model(model_name='scoring_explainer', model_path='raw_scoring_explainer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Run\n",
    "\n",
    "try:\n",
    "    automl_run\n",
    "    print(\"use existing run\")\n",
    "except NameError:\n",
    "    print(\"get a run\")\n",
    "    automl_run = Run(experiment, run_id = '{specify_target_run_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registered_model = automl_run.register_model(\n",
    "    model_name=consts.model_name_automl,\n",
    "    tags={\"trainedIn\":\"pipeline\", \"trainedBy\":\"automl\"},\n",
    "    description='AutoML model for predicting taxi trip duration')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the model, make some predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    model\n",
    "    print(\"use existing model\")\n",
    "except NameError:   \n",
    "    print(\"get the model\")\n",
    "    registered_model = Model(ws, consts.model_name_automl)\n",
    "    registered_model.download(target_dir=DOWNLOAD_PATH)\n",
    "    downloaded_model = joblib.load(os.path.join(DOWNLOAD_PATH, consts.model_name_automl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input is an array of datapoints, each has an array of features\n",
    "input_sample = pd.DataFrame(data=[\n",
    "    {'vendorID': 1, 'passengerCount': 1, 'tripDistance': 1.00, 'pickupLongitude': -73.957909, 'pickupLatitude': 40.670761, \n",
    "     'dropoffLongitude': -73.952194, 'dropoffLatitude': 40.662312, 'totalAmount': 8.15, 'month_num': 1, \n",
    "     'day_of_month': 17, 'day_of_week': 5, 'hour_of_day': 1}])\n",
    "# output is an array of predictions\n",
    "output_sample = model.predict(input_sample)\n",
    "output_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the model as a web service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automl can be deployed without code in the portal\n",
    "# the env file and scoring file are auto-generated, and can be found in the \"Outputs\" of the \"Run\"\n",
    "inference_env = Environment.from_conda_specification(\n",
    "    name = consts.inference_environment_name,\n",
    "    file_path = os.path.join(CODE_PATH, 'inference_automl_env.yml'))\n",
    "inference_config = InferenceConfig(source_directory = CODE_PATH,\n",
    "                                   entry_script = 'score_automl.py',\n",
    "                                   environment = inference_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aks_target = AksCompute(ws, inference_target_name)\n",
    "deployment_config = AksWebservice.deploy_configuration(\n",
    "    cpu_cores = 1, memory_gb = 2, collect_model_data=False, enable_app_insights=False)\n",
    "\n",
    "try: \n",
    "    service = Webservice(ws, consts.service_name_automl)\n",
    "    print(\"Service {} exists, update it\".format(consts.service_name_automl))\n",
    "    service.update(models=[scoring_explainer_model, registered_model], inference_config=inference_config)\n",
    "except:\n",
    "    print('deploy a new service {}'.format(consts.service_name_automl))\n",
    "    service = Model.deploy(ws, consts.service_name_automl, [scoring_explainer_model, registered_model], inference_config, deployment_config, aks_target)\n",
    "    #service.wait_for_deployment(show_output = True)\n",
    "    #print(service.state)\n",
    "    #print(service.get_logs())\n",
    "\n",
    "#print(service.scoring_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test against the deployed service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "if service.auth_enabled:\n",
    "    headers['Authorization'] = 'Bearer '+service.get_keys()[0]\n",
    "elif service.token_auth_enabled:\n",
    "    headers['Authorization'] = 'Bearer '+service.get_token()[0]\n",
    "\n",
    "print(headers)\n",
    "\n",
    "test_sample = '{\"data\": [\\\n",
    "    {\"vendorID\": 1, \"passengerCount\": 2, \"tripDistance\": 1.00, \"pickupLongitude\": -73.957909, \"pickupLatitude\": 40.670761, \\\n",
    "     \"dropoffLongitude\": -73.952194, \"dropoffLatitude\": 40.662312, \"totalAmount\": 8.15, \"month_num\": 1, \\\n",
    "     \"day_of_month\": 17, \"day_of_week\": 5, \"hour_of_day\": 1}]}'\n",
    "\n",
    "response = requests.post(service.scoring_uri, data=test_sample, headers=headers)\n",
    "print(response.status_code)\n",
    "print(response.json())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
